{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gennaro-Farina/Advanced-Natural-Language-Processing-with-TensorFlow-2/blob/master/uncertainty_quantification_with_sngp_bert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs3a5tGVAWGI"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "HYfsarcYBJQp"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOpqCFEyBQDd"
      },
      "source": [
        "# Uncertainty-aware Deep Language Learning with BERT-SNGP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MlSYP6cBT61"
      },
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/text/tutorials/uncertainty_quantification_with_sngp_bert\"><img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/text/blob/master/docs/tutorials/uncertainty_quantification_with_sngp_bert.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/text/blob/master/docs/tutorials/uncertainty_quantification_with_sngp_bert.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/text/docs/tutorials/uncertainty_quantification_with_sngp_bert.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\"><img src=\"https://www.tensorflow.org/images/hub_logo_32px.png\" />See TF Hub model</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IM5IzM26GBh"
      },
      "source": [
        "In the [SNGP tutorial](https://www.tensorflow.org/tutorials/understanding/sngp), you learned how to build SNGP model on top of a deep residual network to improve its ability to quantify its uncertainty. In this tutorial, you will apply SNGP to a natural language understanding (NLU) task by building it on top of a deep BERT encoder to improve deep NLU model's ability in detecting out-of-scope queries. \n",
        "\n",
        "Specifically, you will:\n",
        "* Build BERT-SNGP, a SNGP-augmented [BERT](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2) model.\n",
        "* Load the [CLINC Out-of-scope (OOS)](https://www.tensorflow.org/datasets/catalog/clinc_oos) intent detection dataset.\n",
        "* Train the BERT-SNGP model.\n",
        "* Evaluate the BERT-SNGP model's performance in uncertainty calibration and out-of-domain detection.\n",
        "\n",
        "Beyond CLINC OOS, the SNGP model has been applied to large-scale datasets such as [Jigsaw toxicity detection](https://www.tensorflow.org/datasets/catalog/wikipedia_toxicity_subtypes), and to the image datasets such as [CIFAR-100](https://www.tensorflow.org/datasets/catalog/cifar100) and [ImageNet](https://www.tensorflow.org/datasets/catalog/imagenet2012). \n",
        "For benchmark results of SNGP and other uncertainty methods, as well as high-quality implementation with end-to-end training / evaluation scripts, you can check out the [Uncertainty Baselines](https://github.com/google/uncertainty-baselines) benchmark."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bsids4eAYYI"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l2dCK-rbYXsb"
      },
      "outputs": [],
      "source": [
        "!pip uninstall -y tensorflow tf-text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmlftNekWmKR"
      },
      "outputs": [],
      "source": [
        "!pip install \"tensorflow-text==2.8.*\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sgnLBKk7iuR"
      },
      "outputs": [],
      "source": [
        "!pip install -U tf-models-official==2.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M42dnVSk7dVy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn.metrics\n",
        "import sklearn.calibration\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "import official.nlp.modeling.layers as layers\n",
        "import official.nlp.optimization as optimization\n",
        "\n",
        "import sklearn\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TiolAXow5Rs"
      },
      "source": [
        "This tutorial needs the GPU to run efficiently. Check if the GPU is available. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18dxUFtEBeIR"
      },
      "outputs": [],
      "source": [
        "tf.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9enQL-rZxGkP"
      },
      "outputs": [],
      "source": [
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "gpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY_xLQnS-6ar"
      },
      "outputs": [],
      "source": [
        "assert gpus, \"\"\"\n",
        "  No GPU(s) found! This tutorial will take many hours to run without a GPU.\n",
        "\n",
        "  You may hit this error if the installed tensorflow package is not\n",
        "  compatible with the CUDA and CUDNN versions.\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cnRQfguq6GZj"
      },
      "source": [
        "First implement a standard BERT classifier following the [classify text with BERT](https://www.tensorflow.org/tutorials/text/classify_text_with_bert) tutorial. We will use the [BERT-base](https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3) encoder, and the built-in [`ClassificationHead`](https://github.com/tensorflow/models/blob/master/official/nlp/modeling/layers/cls_head.py) as the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNBEGs7s6NHB"
      },
      "outputs": [],
      "source": [
        "#@title Standard BERT model\n",
        "\n",
        "PREPROCESS_HANDLE = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "MODEL_HANDLE = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3'\n",
        "\n",
        "class BertClassifier(tf.keras.Model):\n",
        "  def __init__(self, \n",
        "               num_classes=150, inner_dim=768, dropout_rate=0.1,\n",
        "               **classifier_kwargs):\n",
        "    \n",
        "    super().__init__()\n",
        "    self.classifier_kwargs = classifier_kwargs\n",
        "\n",
        "    # Initiate the BERT encoder components.\n",
        "    self.bert_preprocessor = hub.KerasLayer(PREPROCESS_HANDLE, name='preprocessing')\n",
        "    self.bert_hidden_layer = hub.KerasLayer(MODEL_HANDLE, trainable=True, name='bert_encoder')\n",
        "\n",
        "    # Defines the encoder and classification layers.\n",
        "    self.bert_encoder = self.make_bert_encoder()\n",
        "    self.classifier = self.make_classification_head(num_classes, inner_dim, dropout_rate)\n",
        "\n",
        "  def make_bert_encoder(self):\n",
        "    text_inputs = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
        "    encoder_inputs = self.bert_preprocessor(text_inputs)\n",
        "    encoder_outputs = self.bert_hidden_layer(encoder_inputs)\n",
        "    return tf.keras.Model(text_inputs, encoder_outputs)\n",
        "\n",
        "  def make_classification_head(self, num_classes, inner_dim, dropout_rate):\n",
        "    return layers.ClassificationHead(\n",
        "        num_classes=num_classes, \n",
        "        inner_dim=inner_dim,\n",
        "        dropout_rate=dropout_rate,\n",
        "        **self.classifier_kwargs)\n",
        "\n",
        "  def call(self, inputs, **kwargs):\n",
        "    encoder_outputs = self.bert_encoder(inputs)\n",
        "    classifier_inputs = encoder_outputs['sequence_output']\n",
        "    return self.classifier(classifier_inputs, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbhbNbKk6WNR"
      },
      "source": [
        "### Build SNGP model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7YakN0V6Oif"
      },
      "source": [
        "To implement a BERT-SNGP model, you only need to replace the `ClassificationHead` with the built-in [`GaussianProcessClassificationHead`](https://github.com/tensorflow/models/blob/master/official/nlp/modeling/layers/cls_head.py). Spectral normalization is already pre-packaged into this classification head. Like in the [SNGP tutorial](https://www.tensorflow.org/tutorials/uncertainty/sngp), add a covariance reset callback to the model, so the model automatically reset the covariance estimator at the beginning of a new epoch to avoid counting the same data twice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCaJy85y8WeE"
      },
      "outputs": [],
      "source": [
        "class ResetCovarianceCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def on_epoch_begin(self, epoch, logs=None):\n",
        "    \"\"\"Resets covariance matrix at the beginning of the epoch.\"\"\"\n",
        "    if epoch > 0:\n",
        "      self.model.classifier.reset_covariance_matrix()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YoHgOuiZ6Q4y"
      },
      "outputs": [],
      "source": [
        "class SNGPBertClassifier(BertClassifier):\n",
        "\n",
        "  def make_classification_head(self, num_classes, inner_dim, dropout_rate):\n",
        "    return layers.GaussianProcessClassificationHead(\n",
        "        num_classes=num_classes, \n",
        "        inner_dim=inner_dim,\n",
        "        dropout_rate=dropout_rate,\n",
        "        gp_cov_momentum=-1,\n",
        "        temperature=30.,\n",
        "        **self.classifier_kwargs)\n",
        "\n",
        "  def fit(self, *args, **kwargs):\n",
        "    \"\"\"Adds ResetCovarianceCallback to model callbacks.\"\"\"\n",
        "    kwargs['callbacks'] = list(kwargs.get('callbacks', []))\n",
        "    kwargs['callbacks'].append(ResetCovarianceCallback())\n",
        "\n",
        "    return super().fit(*args, **kwargs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOj5YWTt6dCe"
      },
      "source": [
        "Note: The `GaussianProcessClassificationHead` takes a new argument `temperature`. It corresponds to the $\\lambda$ parameter in the __mean-field approximation__ introduced in the [SNGP tutorial](https://www.tensorflow.org/tutorials/understanding/sngp). In practice, this value is usually treated as a hyperparameter, and is finetuned to optimize the model's calibration performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdU90uDT6hFq"
      },
      "source": [
        "### Load CLINC OOS dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnuNeyHw6kH7"
      },
      "source": [
        "Now load the [CLINC OOS](https://www.tensorflow.org/datasets/catalog/clinc_oos) intent detection dataset. This dataset contains 15000 user's spoken queries collected over 150 intent classes, it also contains 1000 out-of-domain (OOD) sentences that are not covered by any of the known classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkMZN2iA6hhg"
      },
      "outputs": [],
      "source": [
        "(clinc_train, clinc_test, clinc_test_oos, clinc_validation), ds_info = tfds.load(\n",
        "    'clinc_oos', split=['train', 'test', 'test_oos', 'validation'], with_info=True, batch_size=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJSL2nm8Bo02"
      },
      "source": [
        "Make the train and test data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples = clinc_train['text']\n",
        "train_labels = clinc_train['intent']"
      ],
      "metadata": {
        "id": "XHeZxcQRUysN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#     train_examples.numpy(), train_labels.numpy(), test_size=0.20, random_state=42\n",
        "# )"
      ],
      "metadata": {
        "id": "qbSn0wFmU1bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_examples = clinc_validation['text']\n",
        "val_labels = clinc_validation['intent']\n",
        "\n",
        "ind_val_data = (val_examples, val_labels)"
      ],
      "metadata": {
        "id": "dzHUnj9htCtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cgkOOZOq6fQL"
      },
      "outputs": [],
      "source": [
        "test_examples = clinc_test['text']\n",
        "test_labels = clinc_test['intent']\n",
        "\n",
        "# Makes the in-domain (IND) evaluation data.\n",
        "ind_test_data = (test_examples, test_labels)\n",
        "\n",
        "print('num intents {} :\\n {}'.format(len(np.unique(clinc_test['intent_name'])),\n",
        "                       clinc_test['intent_name']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ind_test_data"
      ],
      "metadata": {
        "id": "eKuHFg8bQvbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw76f6caBq_E"
      },
      "source": [
        "Create a OOD evaluation dataset. For this, combine the in-domain test data `clinc_test` and the out-of-domain data `clinc_test_oos`. We will also assign label 0 to the in-domain examples, and label 1 to the out-of-domain examples. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVFuzecR64FJ"
      },
      "outputs": [],
      "source": [
        "test_data_size = ds_info.splits['test'].num_examples\n",
        "oos_data_size = ds_info.splits['test_oos'].num_examples\n",
        "\n",
        "# Combines the in-domain and out-of-domain test examples.\n",
        "oos_texts = tf.concat([clinc_test['text'], clinc_test_oos['text']], axis=0)\n",
        "oos_labels = tf.constant([0] * test_data_size + [1] * oos_data_size)\n",
        "\n",
        "# Converts into a TF dataset.\n",
        "ood_eval_dataset = tf.data.Dataset.from_tensor_slices(\n",
        "    {\"text\": oos_texts, \"label\": oos_labels})\n",
        "\n",
        "ood_eval_dataset_inscope = tf.data.Dataset.from_tensor_slices(\n",
        "    {\"text\": oos_texts[:test_data_size], \"label\": oos_labels[:test_data_size]})\n",
        "\n",
        "ood_eval_dataset_oos = tf.data.Dataset.from_tensor_slices(\n",
        "    {\"text\": oos_texts[-oos_data_size:], \"label\": oos_labels[-oos_data_size:]})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcHwfwfU6qCE"
      },
      "source": [
        "### Train and evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VTY6KYc6sBB"
      },
      "source": [
        "First set up the basic training configurations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_-uUkUtk6qWC"
      },
      "outputs": [],
      "source": [
        "TRAIN_EPOCHS = 10\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tiEjMdFV6wXQ"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "def bert_optimizer(learning_rate, \n",
        "                   batch_size=TRAIN_BATCH_SIZE, epochs=TRAIN_EPOCHS, \n",
        "                   warmup_rate=0.1):\n",
        "  \"\"\"Creates an AdamWeightDecay optimizer with learning rate schedule.\"\"\"\n",
        "  train_data_size = ds_info.splits['train'].num_examples\n",
        "  \n",
        "  steps_per_epoch = int(train_data_size / batch_size)\n",
        "  num_train_steps = steps_per_epoch * epochs\n",
        "  num_warmup_steps = int(warmup_rate * num_train_steps)  \n",
        "\n",
        "  # Creates learning schedule.\n",
        "  lr_schedule = tf.keras.optimizers.schedules.PolynomialDecay(\n",
        "      initial_learning_rate=learning_rate,\n",
        "      decay_steps=num_train_steps,\n",
        "      end_learning_rate=0.0)  \n",
        "  \n",
        "  return optimization.AdamWeightDecay(\n",
        "      learning_rate=lr_schedule,\n",
        "      weight_decay_rate=0.01,\n",
        "      epsilon=1e-6,\n",
        "      exclude_from_weight_decay=['LayerNorm', 'layer_norm', 'bias'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX_Hzl3l6w-H"
      },
      "outputs": [],
      "source": [
        "optimizer = bert_optimizer(learning_rate=1e-4)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metrics = tf.metrics.SparseCategoricalAccuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ptn9Cupe6z7o"
      },
      "outputs": [],
      "source": [
        "fit_configs = dict(batch_size=TRAIN_BATCH_SIZE,\n",
        "                   epochs=TRAIN_EPOCHS,\n",
        "                   validation_batch_size=EVAL_BATCH_SIZE, \n",
        "                   validation_data=ind_test_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model = BertClassifier()\n",
        "bert_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "bert_model.fit(train_examples, train_labels, **fit_configs)"
      ],
      "metadata": {
        "id": "iPHsR7YlUdTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out = bert_model.evaluate(test_examples, test_labels)"
      ],
      "metadata": {
        "id": "Ne5TbVnXWzcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_out"
      ],
      "metadata": {
        "id": "lhGIWR5-W5lb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_predicted_labels = bert_model.predict(test_examples)"
      ],
      "metadata": {
        "id": "p_ybzf_FXAU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_f1_macro_score = sklearn.metrics.f1_score(test_labels,\n",
        "                         tf.math.argmax(bert_predicted_labels, axis=1),\n",
        "                         average='macro'\n",
        "                        )\n",
        "\n",
        "bert_cm = sklearn.metrics.confusion_matrix(test_labels,\n",
        "                                 tf.math.argmax(bert_predicted_labels, axis=1)\n",
        "                                 )\n",
        "\n",
        "test_label = clinc_test['intent']\n",
        "test_name  = clinc_test['intent_name']\n",
        "labels_names_dict = {i: t for i, t in zip(test_label.numpy(), test_name.numpy())}\n",
        "labels_names_dict_sorted = {i:labels_names_dict[i] for i in sorted(labels_names_dict)}\n",
        "\n",
        "df_cm = pd.DataFrame(bert_cm,\n",
        "                     index = [i for _, i in labels_names_dict_sorted.items()],\n",
        "                     columns = [i for _, i in labels_names_dict_sorted.items()])\n",
        "plt.figure(figsize = (100,70))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('confusion_matrix_BERT_HEAD.png', dpi=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jcl_zDckXMyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ZK5PBwW61jd"
      },
      "outputs": [],
      "source": [
        "sngp_model = SNGPBertClassifier()\n",
        "sngp_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "sngp_model.fit(train_examples, train_labels, **fit_configs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels"
      ],
      "metadata": {
        "id": "Nk_3EIDovpK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sngp_out = sngp_model.evaluate(test_examples, test_labels)"
      ],
      "metadata": {
        "id": "DuAohrdS0mkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sngp_out"
      ],
      "metadata": {
        "id": "rX3IsDDz2ljg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_labels = sngp_model.predict(test_examples)"
      ],
      "metadata": {
        "id": "1cz477uV5PXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for test_label in test_labels:\n",
        "#   print(test_label)"
      ],
      "metadata": {
        "id": "jayS4Fld46Bm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.math.argmax(predicted_labels, axis=1)"
      ],
      "metadata": {
        "id": "2gt1PHYe6BVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1_macro_score = sklearn.metrics.f1_score(test_labels,\n",
        "                         tf.math.argmax(predicted_labels, axis=1),\n",
        "                         average='macro'\n",
        "                        )\n",
        "\n",
        "cm = sklearn.metrics.confusion_matrix(test_labels,\n",
        "                                 tf.math.argmax(predicted_labels, axis=1)\n",
        "                                 )\n",
        "\n",
        "test_label = clinc_test['intent']\n",
        "test_name  = clinc_test['intent_name']\n",
        "labels_names_dict = {i: t for i, t in zip(test_label.numpy(), test_name.numpy())}\n",
        "labels_names_dict_sorted = {i:labels_names_dict[i] for i in sorted(labels_names_dict)}\n",
        "\n",
        "df_cm = pd.DataFrame(cm, index = [i for _, i in labels_names_dict_sorted.items()],\n",
        "                  columns = [i for _, i in labels_names_dict_sorted.items()])\n",
        "plt.figure(figsize = (100,70))\n",
        "sn.heatmap(df_cm, annot=True)\n",
        "plt.savefig('confusion_matrix_SNGP_HEAD.png', dpi=100)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U3T5-ZMY6lSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds_info"
      ],
      "metadata": {
        "id": "o11MPQDMAC2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpDsgTYx63tO"
      },
      "source": [
        "### Evaluate OOD performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5NGVe7L67bB"
      },
      "source": [
        "Evaluate how well the model can detect the unfamiliar out-of-domain queries. For rigorous evaluation, use the OOD evaluation dataset `ood_eval_dataset` built earlier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyLgt_lL7APo"
      },
      "outputs": [],
      "source": [
        "#@title\n",
        "\n",
        "def oos_predict(model, ood_eval_dataset, **model_kwargs):\n",
        "  oos_labels = []\n",
        "  oos_probs = []\n",
        "\n",
        "  ood_eval_dataset = ood_eval_dataset.batch(EVAL_BATCH_SIZE)\n",
        "  for oos_batch in ood_eval_dataset:\n",
        "    oos_text_batch = oos_batch[\"text\"]\n",
        "    oos_label_batch = oos_batch[\"label\"] \n",
        "\n",
        "    pred_logits = model(oos_text_batch, **model_kwargs)\n",
        "    pred_probs_all = tf.nn.softmax(pred_logits, axis=-1)\n",
        "    pred_probs = tf.reduce_max(pred_probs_all, axis=-1)\n",
        "\n",
        "    oos_labels.append(oos_label_batch)\n",
        "    oos_probs.append(pred_probs)\n",
        "\n",
        "  oos_probs = tf.concat(oos_probs, axis=0)\n",
        "  oos_labels = tf.concat(oos_labels, axis=0) \n",
        "\n",
        "  return oos_probs, oos_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmc2tVXs6_uo"
      },
      "source": [
        "Computes the OOD probabilities as $1 - p(x)$, where $p(x)=softmax(logit(x))$ is the predictive probability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9aFVVDO7C7o"
      },
      "outputs": [],
      "source": [
        "sngp_probs, ood_labels = oos_predict(sngp_model, ood_eval_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def oos_predict2(model, ood_eval_dataset, **model_kwargs):\n",
        "  oos_labels = []\n",
        "  oos_probs = []\n",
        "\n",
        "  ood_eval_dataset = ood_eval_dataset.batch(EVAL_BATCH_SIZE)\n",
        "  for oos_batch in ood_eval_dataset:\n",
        "    oos_text_batch = oos_batch[\"text\"]\n",
        "    # print('oos_batch[\"label\"]: ', oos_batch[\"label\"] )\n",
        "    oos_label_batch = oos_batch[\"label\"] \n",
        "\n",
        "    pred_logits = model(oos_text_batch, **model_kwargs)\n",
        "    # print(pred_logits.shape)\n",
        "    pred_probs_all = tf.nn.softmax(pred_logits, axis=-1)\n",
        "\n",
        "    pred_probs = tf.reduce_max(pred_probs_all, axis=-1)\n",
        "\n",
        "    # print('sngp_probs: ', pred_probs_all)\n",
        "    for pred, text, lbl, prob in zip(pred_logits, oos_text_batch, oos_label_batch, pred_probs):  \n",
        "      # print('pred: {}\\n prob_sum: {} pred_lbl: {} text: {}\\n lbl: {}\\n\\n\\n '.format(pred,\n",
        "      #                                                                               np.sum(pred_probs),\n",
        "      #                                                                               np.argmax(pred_probs),\n",
        "      #                                                                               text,\n",
        "      #                                                                               lbl))\n",
        "      \n",
        "      print('prob: {:2.2f} argmax: {}  text: {} '.format( np.max(prob), labels_names_dict[np.argmax(pred)], text, ))\n",
        "\n",
        "    oos_labels.append(oos_label_batch)\n",
        "    oos_probs.append(pred_probs)\n",
        "\n",
        "  oos_probs = tf.concat(oos_probs, axis=0)\n",
        "  oos_labels = tf.concat(oos_labels, axis=0) \n",
        "\n",
        "  return oos_probs, oos_labels\n",
        "\n",
        "# print('NO SNGP MODEL ***************************')\n",
        "# print('inscope_results: ')\n",
        "# sngp_probs, ood_labels = oos_predict2(bert_model, ood_eval_dataset_inscope)\n",
        "# # print('ood_labels: ', ood_labels)\n",
        "\n",
        "# print('oos_results: ')\n",
        "# sngp_probs, ood_labels = oos_predict2(bert_model, ood_eval_dataset_oos)\n",
        "# # print('ood_labels: ', ood_labels)\n",
        "\n",
        "print('\\n\\n\\n')\n",
        "print('SNGP MODEL ***************************')\n",
        "# print('inscope_results: ')\n",
        "# sngp_probs, ood_labels = oos_predict2(sngp_model, ood_eval_dataset_inscope)\n",
        "# # print('ood_labels: ', ood_labels)\n",
        "\n",
        "print('oos_results: ')\n",
        "sngp_probs, ood_labels = oos_predict2(sngp_model, ood_eval_dataset_oos)\n",
        "# print('ood_labels: ', ood_labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "5yAjmXZhbvVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for oos_batch in ood_eval_dataset:\n",
        "  oos_text_batch = oos_batch[\"text\"]\n",
        "  oos_label_batch = oos_batch[\"label\"] \n",
        "  print(oos_text_batch, oos_label_batch)"
      ],
      "metadata": {
        "id": "i-7JV2PM0h1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sngp_model.save('sngp_model_10epochs')"
      ],
      "metadata": {
        "id": "D0QwL0EOmQWE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sngp_model2 = tf.keras.models.load_model('sngp_model_10epochs', custom_objects={'AdamWeightDecay':optimizer})"
      ],
      "metadata": {
        "id": "Pijh4dx3nLeI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sngp_probs, ood_labels = oos_predict2(sngp_model2, ood_eval_dataset_oos)\n",
        "# print('ood_labels: ', ood_labels)"
      ],
      "metadata": {
        "id": "WeOaxQY2oDQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! zip -r sngp_model_10_epochs sngp_model_10epochs/*"
      ],
      "metadata": {
        "id": "D1Fo0LWCmfAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PC0wwZp7GJD"
      },
      "outputs": [],
      "source": [
        "ood_probs = 1 - sngp_probs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsandMTX7HjX"
      },
      "source": [
        "Now evaluate how well the model's uncertainty score `ood_probs` predicts the out-of-domain label. First compute the Area under precision-recall curve (AUPRC) for OOD probability v.s. OOD detection accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0u5Wx8AP7Mdx"
      },
      "outputs": [],
      "source": [
        "precision, recall, _ = sklearn.metrics.precision_recall_curve(ood_labels, ood_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "axcctOsh7N5A"
      },
      "outputs": [],
      "source": [
        "auprc = sklearn.metrics.auc(recall, precision)\n",
        "print(f'SNGP AUPRC: {auprc:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_GEqxq-7Q1Y"
      },
      "source": [
        "This matches the SNGP performance reported at the CLINC OOS benchmark under the [Uncertainty Baselines](https://github.com/google/uncertainty-baselines)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8H4vYcyd7Ux2"
      },
      "source": [
        "Next, examine the model's quality in [uncertainty calibration](https://scikit-learn.org/stable/modules/calibration.html), i.e., whether the model's predictive probability corresponds to its predictive accuracy. A well-calibrated model is considered trust-worthy, since, for example, its predictive probability $p(x)=0.8$ means that the model is correct 80% of the time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5GxrSWJ7SYn"
      },
      "outputs": [],
      "source": [
        "prob_true, prob_pred = sklearn.calibration.calibration_curve(\n",
        "    ood_labels, ood_probs, n_bins=10, strategy='quantile')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozzJM-D-7XVq"
      },
      "outputs": [],
      "source": [
        "plt.plot(prob_pred, prob_true)\n",
        "\n",
        "plt.plot([0., 1.], [0., 1.], c='k', linestyle=\"--\")\n",
        "plt.xlabel('Predictive Probability')\n",
        "plt.ylabel('Predictive Accuracy')\n",
        "plt.title('Calibration Plots, SNGP')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36M6HeHx7ZI4"
      },
      "source": [
        "## Resources and further reading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdFTpyaP0A-N"
      },
      "source": [
        "* See the [SNGP tutorial](https://www.tensorflow.org/tutorials/understanding/sngp) for a detailed walkthrough of implementing SNGP from scratch. \n",
        "* See [Uncertainty Baselines](https://github.com/google/uncertainty-baselines)  for the implementation of SNGP model (and many other uncertainty methods) on a wide variety of benchmark datasets (e.g., [CIFAR](https://www.tensorflow.org/datasets/catalog/cifar100), [ImageNet](https://www.tensorflow.org/datasets/catalog/imagenet2012), [Jigsaw toxicity detection](https://www.tensorflow.org/datasets/catalog/wikipedia_toxicity_subtypes), etc).\n",
        "* For a deeper understanding of the SNGP method, check out the paper [Simple and Principled Uncertainty Estimation with Deterministic Deep Learning via Distance Awareness](https://arxiv.org/abs/2006.10108).\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}